{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74d958cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "unique_addresses_len =  40324960\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import socket\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from array import *\n",
    "import csv\n",
    "import random\n",
    "from tqdm import tqdm\n",
    "\n",
    "# using datetime module\n",
    "import datetime;\n",
    "\n",
    "# Binary Search\n",
    "from bisect import bisect_left\n",
    "from bisect import bisect_right\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Process, Queue\n",
    "import queue\n",
    "import threading\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "#https://python-louvain.readthedocs.io/en/latest/api.html\n",
    "#community.modularity(partition, graph, weight='weight')\n",
    "from community import modularity\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "#unique_addresses_len = len(unique_addresses)\n",
    "unique_addresses_len = 40324960\n",
    "print('unique_addresses_len = ', unique_addresses_len)\n",
    "\n",
    "print('----------------------')\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38c1ce57-facb-41bd-9372-3a829c11cffe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7481c483-a9cf-420e-bf73-809576d6286d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('----------------------')\n",
    "\n",
    "#print(os.path.basename(\"/path/to/some/file.txt\"))\n",
    "#print(os.path.dirname(\"/path/to/some/file.txt\"))\n",
    "\n",
    "#BASE_ADDRESS = '/local/scratch/exported/parsed_blockchains/cardano_mostafa/'\n",
    "BASE_ADDRESS = '/local/scratch/exported/blockchain_parsed/cardano_mostafa/'\n",
    "TEMP_ADDRESS = BASE_ADDRESS + '/temp_files/'\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a70a84-0b85-426c-adf1-82569661fc43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c26540b-e059-430f-afc3-f03f7ac60b25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "##########################################################################################\n",
    "def BinarySearch(a, x):\n",
    "    i = bisect_left(a, x)\n",
    "    if i < len(a) and a[i] == x:\n",
    "        return i\n",
    "    else:\n",
    "        print('BinarySearch Error: -1')\n",
    "        return -1\n",
    "\n",
    "##########################################################################################\n",
    "def BinarySearch_Find_start_end(a, x):\n",
    "    i = bisect_left(a, x)\n",
    "    j = bisect_right(a, x) - 1\n",
    "    if i < len(a) and a[i] == x and j < len(a) and a[j] == x:\n",
    "        return [i, j]\n",
    "    else:\n",
    "        print('BinarySearch Error: -1')\n",
    "        print('i = ', i)\n",
    "        print('j = ', j)\n",
    "        return -1\n",
    "\n",
    "##########################################################################################\n",
    "def store_array_to_file_2D (input_array_name, file_name):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Store Array 2D to ' + file_name + '): ', ct)\n",
    "\n",
    "    with open(file_name, \"w\") as filehandle:\n",
    "        json.dump(input_array_name, filehandle)\n",
    "    \n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Store Array 2D to ' + file_name + '): ', et)\n",
    "\n",
    "    return\n",
    "\n",
    "##########################################################################################\n",
    "def load_file_to_array_2D (file_name):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Load ' + file_name  + ' to Array 2D): ', ct)\n",
    "\n",
    "    with open(file_name) as filehandle:\n",
    "        output_array_name = json.load(filehandle)\n",
    "\n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Load ' + file_name  + ' to Array 2D): ', et)\n",
    "    \n",
    "    return output_array_name\n",
    "\n",
    "##########################################################################################\n",
    "def store_dict_to_file_INT (input_dict_name, file_name):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Store Dictionary to ' + file_name + '): ', ct)\n",
    "\n",
    "    filehandle = csv.writer(open(file_name, 'w'))\n",
    "    for key, val in input_dict_name.items():\n",
    "        filehandle.writerow([key, val])\n",
    "\n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Store Dictionary to ' + file_name + '): ', et)\n",
    "\n",
    "    return\n",
    "\n",
    "##########################################################################################\n",
    "def load_file_to_dict_INT (file_name):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Load ' + file_name  + ' to Dictionary): ', ct)\n",
    "\n",
    "    filehandle = csv.reader(open(file_name, 'r'))\n",
    "    output_dict_name = {int(rows[0]):int(rows[1]) for rows in filehandle}\n",
    "\n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Load ' + file_name  + ' to Dictionary): ', et)\n",
    "    \n",
    "    return output_dict_name\n",
    "\n",
    "##########################################################################################\n",
    "def BinarySearch_Find_start_end(a, x):\n",
    "    i = bisect_left(a, x)\n",
    "    j = bisect_right(a, x) - 1\n",
    "    if i < len(a) and a[i] == x and j < len(a) and a[j] == x:\n",
    "        return [i, j]\n",
    "    else:\n",
    "        print('BinarySearch Error: -1')\n",
    "        print('i = ', i)\n",
    "        print('j = ', j)\n",
    "        return -1\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "def find_weights_graphEdges(graghEdges_array, graph_weights):\n",
    "    if (len(graghEdges_array) != len(graph_weights)):\n",
    "        print('find_weights_graphEdges Error: -1 (Length)')\n",
    "        return -1\n",
    "    \n",
    "    #for i in range(len(graghEdges_array)):\n",
    "    for i in tqdm(range(len(graghEdges_array))):\n",
    "        nodes = np.unique(graghEdges_array[i])\n",
    "        edges = graghEdges_array[i]\n",
    "        edges.sort()\n",
    "        \n",
    "        for j in nodes:\n",
    "            # (j,w)=weighted edge: j=node number, w=weight\n",
    "            x = BinarySearch_Find_start_end(edges, j)\n",
    "            w = x[1] - x[0] + 1\n",
    "            graph_weights[i].append((i,j,w)) \n",
    "        \n",
    "        #if (i % 1000000 == 0):\n",
    "        #    print('One milion records done!' , i)\n",
    "\n",
    "    return\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2954a8-740e-4277-b11b-84c47c184cab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0c954e0-516a-4677-b505-7f4f5adf4481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa//graphEdgesArrayList_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-02-25_224222.txt to Array 2D):  2023-02-25 23:17:33.722377\n",
      "elapsed time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa//graphEdgesArrayList_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-02-25_224222.txt to Array 2D):  0:01:01.270444\n",
      "Lenght of \"graphEdges_merged\" =  40324960\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Load graphEdges_merged from file:\n",
    "\n",
    "graphEdges_merged = load_file_to_array_2D(BASE_ADDRESS + '/graphEdgesArrayList_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-02-25_224222.txt')\n",
    "\n",
    "print('Lenght of \\\"graphEdges_merged\\\" = ', len(graphEdges_merged))\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef67edb-f41d-4c79-a839-f0c3319a2465",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b8bac4-df9e-4649-9beb-b6eef74d7089",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "current time:  2023-02-25 23:19:26.558957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40324960/40324960 [21:18<00:00, 31545.98it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Total elapsed time (Calculate graph_weights):  0:21:47.127427\n",
      "----------------------\n",
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Calculate graph_weights:\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "graph_weights = [[] for _ in range(unique_addresses_len)]\n",
    "find_weights_graphEdges(graphEdges_merged, graph_weights)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Calculate graph_weights): \", et)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf5da97-d942-4b57-941b-e96a72c56490",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a90c43ed-f7e9-4996-9ce2-0cb57908d660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "current time:  2023-02-25 23:45:59.196172\n",
      "output_filename =  /local/scratch/exported/blockchain_parsed/cardano_mostafa//graphWeightsArrayList_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-02-25_234559.txt\n",
      "----------------------\n",
      "Total elapsed time (Store graph_weights into file):  0:03:45.033019\n",
      "----------------------\n",
      "done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\\'----------------------\\')\\n# ct stores current time\\nct = datetime.datetime.now()\\nprint(\"current time: \", ct)\\n\\n\\ninput_filename = BASE_ADDRESS + \\'/graphWeightsArrayList_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-01-10_175935.txt\\'\\nprint(\\'input_filename = \\', input_filename)\\n\\n\\ngraph_weights = [[] for _ in range(unique_addresses_len)]\\n\\ni=0\\nwith open(input_filename) as filehandle:\\n    for row in filehandle:\\n        graph_weights[i] = ast.literal_eval(row[:-1])\\n        i = i+1\\n        if (i % 1000000 == 0):\\n            print(\\'One milion records done!\\' , i)\\n\\n\\n##########################################################################################\\nprint(\\'----------------------\\')\\net = datetime.datetime.now() - ct\\nprint(\"Total elapsed time (Store graph_weights into file): \", et)\\n\\n##########################################################################################\\nprint(\\'----------------------\\')\\nprint(\\'done!\\')\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store/Load \"graph_weights\" into/from file:\n",
    "\n",
    "\n",
    "\n",
    "# Store graph_weights into file:\n",
    "'''\n",
    "print('----------------------')\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "output_filename = BASE_ADDRESS + '/graphWeightsArrayList_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "print('output_filename = ', output_filename)\n",
    "\n",
    "with open(output_filename, 'w') as filehandle:\n",
    "        for element in graph_weights:\n",
    "            filehandle.write(f'{element}\\n')\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Store graph_weights into file): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Load graph_weights from file:\n",
    "'''\n",
    "print('----------------------')\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "input_filename = BASE_ADDRESS + '/graphWeightsArrayList_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-02-25_234559.txt'\n",
    "print('input_filename = ', input_filename)\n",
    "\n",
    "\n",
    "graph_weights = [[] for _ in range(unique_addresses_len)]\n",
    "\n",
    "i=0\n",
    "with open(input_filename) as filehandle:\n",
    "    for row in filehandle:\n",
    "        graph_weights[i] = ast.literal_eval(row[:-1])\n",
    "        i = i+1\n",
    "        if (i % 1000000 == 0):\n",
    "            print('One milion records done!' , i)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Store graph_weights into file): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06970d9-06f0-4c52-9a56-edbbed20d9c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9c92a106-349f-4232-9835-e33cd76a98a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "current time:  2023-02-25 23:50:42.464256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40324960/40324960 [13:14<00:00, 50748.92it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "Is Connected    (G) =  False\n",
      "Number of Nodes (G) =  40324960\n",
      "Number of Edges (G) =  260967353\n",
      "----------------------\n",
      "----------------------\n",
      "Degree of node 39057080 =  0\n",
      "graph_weights[39057080] =  []\n",
      "----------------------\n",
      "Degree of node 454231 =  1\n",
      "graph_weights[454231] =  []\n",
      "----------------------\n",
      "Degree of node 397965 =  15\n",
      "graph_weights[397965] =  []\n",
      "----------------------\n",
      "Total elapsed time (Store graph_weights into file):  0:13:34.459617\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Generate \"Graph G Addrs network\" using graph_weights:\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "G = nx.Graph()\n",
    "\n",
    "for i in tqdm(range(len(graph_weights))):\n",
    "    G.add_node(i)\n",
    "    G.add_weighted_edges_from(graph_weights[i])\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('Is Connected    (G) = ', nx.is_connected(G))\n",
    "print('Number of Nodes (G) = ', G.number_of_nodes())\n",
    "print('Number of Edges (G) = ', G.number_of_edges())\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "test_results = [39057080, 454231, 397965]\n",
    "for i in test_results:\n",
    "    print('----------------------')\n",
    "    print('Degree of node ' + str(i) + ' = ', G.degree()[i])\n",
    "    print('graph_weights[' + str(i) + '] = ', graph_weights[i])\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Store graph_weights into file): \", et)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ee08fa-081e-4661-bfb8-8861f7f46bad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "79c50db8-9fd2-402e-9ca3-5031ad438caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "current time:  2023-02-26 00:05:07.105295\n",
      "output_filename =  /local/scratch/exported/blockchain_parsed/cardano_mostafa//Graph_G_AddrsNetwork_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-02-26_000507.pickle\n",
      "----------------------\n",
      "Total elapsed time (Store G into file):  0:20:37.666122\n",
      "----------------------\n",
      "done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\\'----------------------\\')\\n# ct stores current time\\nct = datetime.datetime.now()\\nprint(\"current time: \", ct)\\n\\n\\nimport pickle\\ninput_filename = BASE_ADDRESS + \\'/Graph_G_AddrsNetwork_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-01-18_145225.pickle\\'\\nprint(\\'input_filename = \\', input_filename)\\nG = pickle.load(open(input_filename, \\'rb\\'))\\n\\n\\n##########################################################################################\\nprint(\\'----------------------\\')\\net = datetime.datetime.now() - ct\\nprint(\"Total elapsed time (Load G from file): \", et)\\n\\n##########################################################################################\\nprint(\\'----------------------\\')\\nprint(\\'done!\\')\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store/Load graph object \"Graph G Addrs network\" to/from file:\n",
    "\n",
    "\n",
    "# Store graph object to file:\n",
    "'''\n",
    "print('----------------------')\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "import pickle\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "output_filename = BASE_ADDRESS + '/Graph_G_AddrsNetwork_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__' + curr_timestamp + '.pickle'\n",
    "print('output_filename = ', output_filename)\n",
    "pickle.dump(G, open(output_filename, 'wb'))\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Store G into file): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Load graph object from file:\n",
    "'''\n",
    "print('----------------------')\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "import pickle\n",
    "input_filename = BASE_ADDRESS + '/Graph_G_AddrsNetwork_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-02-26_000507.pickle'\n",
    "print('input_filename = ', input_filename)\n",
    "G = pickle.load(open(input_filename, 'rb'))\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Load G from file): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "536e896e-babe-4f3e-be38-55e72ba1f38b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "980243e5-8917-4bcb-b4a3-0de397c13122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "current time:  2023-02-26 00:28:13.670735\n",
      "Is Connected    (largest_cc_subgraph) =  True\n",
      "Number of Nodes (largest_cc_subgraph) =  1281498\n",
      "Number of Edges (largest_cc_subgraph) =  12949331\n",
      "----------------------\n",
      "Sum Weighted Degrees (largest_cc_subgraph) =  88577042\n",
      "Max Weighted Degrees (largest_cc_subgraph) =  4672736\n",
      "----------------------\n",
      "Number of nodes with Weighted Degree \"1\" =  7591\n",
      "Number of nodes with Weighted Degree \"2\" =  48084\n",
      "Number of nodes with Weighted Degree \"3\" =  96966\n",
      "Number of nodes with Weighted Degree \"4\" =  327661\n",
      "Number of nodes with Weighted Degree \"5\" =  274782\n",
      "Number of nodes with Weighted Degree \"6\" =  1306\n",
      "Number of nodes with Weighted Degree \"7\" =  1337\n",
      "Number of nodes with Weighted Degree \"8\" =  1530\n",
      "Number of nodes with Weighted Degree \"9\" =  1797\n",
      "Number of nodes with Weighted Degree \"10\" =  4106\n",
      "Number of nodes with Weighted Degree \"11\" =  2161\n",
      "Number of nodes with Weighted Degree \"12\" =  9455\n",
      "Number of nodes with Weighted Degree \"13\" =  4409\n",
      "Number of nodes with Weighted Degree \"14\" =  36021\n",
      "----------------------\n",
      "Total elapsed time (Store graph_weights into file):  0:04:51.838745\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Extract the largest connected component:\n",
    "\n",
    "print('----------------------')\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "\n",
    "#largest_cc = max(nx.connected_components(G), key=len)\n",
    "largest_cc = list(sorted(nx.connected_components(G), key=len, reverse=True))[0]\n",
    "largest_cc_subgraph = G.subgraph(largest_cc).copy()\n",
    "\n",
    "print('Is Connected    (largest_cc_subgraph) = ', nx.is_connected(largest_cc_subgraph))\n",
    "print('Number of Nodes (largest_cc_subgraph) = ', largest_cc_subgraph.number_of_nodes())\n",
    "print('Number of Edges (largest_cc_subgraph) = ', largest_cc_subgraph.number_of_edges())\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "# Find weighted degrees of nodes:\n",
    "degree_sequence = sorted((d for n, d in largest_cc_subgraph.degree(weight='weight')), reverse=False)\n",
    "print('Sum Weighted Degrees (largest_cc_subgraph) = ', sum(degree_sequence))\n",
    "print('Max Weighted Degrees (largest_cc_subgraph) = ', max(degree_sequence))\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "for i in range(1, 15):\n",
    "    x = BinarySearch_Find_start_end(degree_sequence, i)\n",
    "    print('Number of nodes with Weighted Degree \\\"' + str(i) + '\\\" = ', x[1] - x[0] + 1)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Store graph_weights into file): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6da07fe-733c-4ae2-a75d-4771574a70cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "064d7591-e1f1-44dc-9990-ddb9dcc27258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "current time:  2023-02-26 00:34:12.594165\n",
      "output_filename =  /local/scratch/exported/blockchain_parsed/cardano_mostafa//largest_cc_subgraph_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-02-26_003412.pickle\n",
      "----------------------\n",
      "Total elapsed time (Store largest_cc_subgraph into file):  0:00:30.019388\n",
      "----------------------\n",
      "done!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprint(\\'----------------------\\')\\n# ct stores current time\\nct = datetime.datetime.now()\\nprint(\"current time: \", ct)\\n\\n\\nimport pickle\\ninput_filename = BASE_ADDRESS + \\'/largest_cc_subgraph_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-01-10_181953.pickle\\'\\nprint(\\'input_filename = \\', input_filename)\\nlargest_cc_subgraph = pickle.load(open(input_filename, \\'rb\\'))\\n\\n\\n##########################################################################################\\nprint(\\'----------------------\\')\\net = datetime.datetime.now() - ct\\nprint(\"Total elapsed time (Load largest_cc_subgraph into file): \", et)\\n\\n##########################################################################################\\nprint(\\'----------------------\\')\\nprint(\\'done!\\')\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Store/Load graph object \"largest_cc_subgraph\" to/from file:\n",
    "\n",
    "\n",
    "# Store graph object to file:\n",
    "'''\n",
    "print('----------------------')\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "import pickle\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "output_filename = BASE_ADDRESS + '/Largest1_cc_subgraph_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__' + curr_timestamp + '.pickle'\n",
    "print('output_filename = ', output_filename)\n",
    "pickle.dump(largest_cc_subgraph, open(output_filename, 'wb'))\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Store largest_cc_subgraph into file): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Load graph object from file:\n",
    "'''\n",
    "print('----------------------')\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "import pickle\n",
    "input_filename = BASE_ADDRESS + '/Largest2_cc_subgraph_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__2023-01-10_181953.pickle'\n",
    "print('input_filename = ', input_filename)\n",
    "largest_cc_subgraph = pickle.load(open(input_filename, 'rb'))\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Load largest_cc_subgraph into file): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9fc0752-8c54-4fcc-b561-39cb1f032858",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0196b88f-d1ef-41e4-b361-78fec9bee9f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbefc9d-a635-41be-9082-cab84672cef2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
