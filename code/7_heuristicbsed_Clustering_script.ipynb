{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3977da8d-b11f-4b49-9da0-48af165a0042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "unique_raw_addresses_len        =  40330345\n",
      "unique_payment_addresses_len    =  40324960\n",
      "unique_delegation_addresses_len =  3868049\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from array import *\n",
    "import csv\n",
    "\n",
    "# using datetime module\n",
    "import datetime;\n",
    "\n",
    "# Binary Search\n",
    "from bisect import bisect_left\n",
    "from bisect import bisect_right\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "\n",
    "import multiprocessing as mp\n",
    "from multiprocessing import Process, Queue\n",
    "from multiprocessing import current_process\n",
    "import queue\n",
    "import threading\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"PYARROW_IGNORE_TIMEZONE\"] = \"1\"\n",
    "from pyspark.sql import SparkSession\n",
    "import pyspark.pandas as ps\n",
    "from pyspark.sql.functions import col\n",
    "import pandas as pd\n",
    "\n",
    "import random\n",
    "import networkx as nx\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "#https://python-louvain.readthedocs.io/en/latest/api.html\n",
    "#community.modularity(partition, graph, weight='weight')\n",
    "from community import modularity\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "#unique_payment_addresses_len = len(unique_payment_addresses)\n",
    "unique_raw_addresses_len        = 40330345\n",
    "unique_payment_addresses_len    = 40324960\n",
    "unique_delegation_addresses_len = 3868049\n",
    "print('unique_raw_addresses_len        = ', unique_raw_addresses_len)\n",
    "print('unique_payment_addresses_len    = ', unique_payment_addresses_len)\n",
    "print('unique_delegation_addresses_len = ', unique_delegation_addresses_len)\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9258c9b8-cfd8-48be-a5a0-bfe08b035128",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7b722f8-b2ad-40fe-8226-a9b3b2bb1ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "print('----------------------')\n",
    "\n",
    "#print(os.path.basename(\"/path/to/some/file.txt\"))\n",
    "#print(os.path.dirname(\"/path/to/some/file.txt\"))\n",
    "\n",
    "BASE_ADDRESS = '/local/scratch/exported/blockchain_parsed/cardano_mostafa'\n",
    "TEMP_ADDRESS = BASE_ADDRESS + '/temp_files/'\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e736672-5c9a-4e51-bb14-64e8f80d8471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "298dd4f7-d484-4158-91a6-0aa9901855d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "current time:  2023-04-07 09:44:45.172985\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Define required methods:\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "def parent (id1, parents_array):\n",
    "    return parents_array[id1];\n",
    "\n",
    "##########################################################################################\n",
    "def find_parent (id1, parents_array):\n",
    "    while (id1 != parent(id1, parents_array)):\n",
    "        new_parent = parent(parent(id1, parents_array), parents_array);\n",
    "        id1        = new_parent;\n",
    "    \n",
    "    return id1\n",
    "\n",
    "##########################################################################################\n",
    "# Link two addresses based on \"Union-Find\" Algorithm:\n",
    "def link_address (addr_position_1, addr_position_2, parents_array):\n",
    "    id1 = find_parent(addr_position_1, parents_array)\n",
    "    id2 = find_parent(addr_position_2, parents_array)\n",
    "\n",
    "    if (id1 == id2):\n",
    "        return\n",
    "\n",
    "    # make sure always we have id1 > id2\n",
    "    if id1 < id2:\n",
    "        x = id1\n",
    "        id1 = id2\n",
    "        id2 = x\n",
    "\n",
    "    parents_array[id1] = id2\n",
    "    return\n",
    "\n",
    "##########################################################################################\n",
    "def resolveAll (parents_array):\n",
    "    for id1 in tqdm(range(len(parents_array))):\n",
    "        parents_array[id1] = find_parent(id1, parents_array);\n",
    "    return\n",
    "\n",
    "##########################################################################################\n",
    "def remapClusterIds (parents_array, clustering_array):\n",
    "    cluster_count = 0\n",
    "    place_holder = 9999999999999\n",
    "    new_cluster_ids = [place_holder] * len(parents_array)\n",
    "    \n",
    "    for i in range(len(clustering_array)):\n",
    "        clustering_array[i] = parents_array[i]\n",
    "\n",
    "    for i in tqdm(range(len(clustering_array))):\n",
    "        parent_index = clustering_array[i]\n",
    "\n",
    "        if (new_cluster_ids [parent_index] == place_holder):\n",
    "            new_cluster_ids [parent_index] = cluster_count\n",
    "            cluster_count = cluster_count + 1\n",
    "\n",
    "        clustering_array[i] = new_cluster_ids [parent_index]\n",
    "\n",
    "    return cluster_count;\n",
    "\n",
    "##########################################################################################\n",
    "def merge_parents(parents_array, parents_merged):\n",
    "    if (len(parents_array) != len(parents_merged)):\n",
    "        print('parents_merged Error: -1 (Length)')\n",
    "        return -1\n",
    "    \n",
    "    for i in tqdm(range(len(parents_merged))):\n",
    "        link_address (i, parents_array[i], parents_merged)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "def BinarySearch(a, x):\n",
    "    i = bisect_left(a, x)\n",
    "    if i < len(a) and a[i] == x:\n",
    "        return i\n",
    "    else:\n",
    "        print('BinarySearch Error: -1')\n",
    "        return -1\n",
    "\n",
    "##########################################################################################\n",
    "def BinarySearch_Find_start_end(a, x):\n",
    "    i = bisect_left(a, x)\n",
    "    j = bisect_right(a, x) - 1\n",
    "    if i < len(a) and a[i] == x and j < len(a) and a[j] == x:\n",
    "        return [i, j]\n",
    "    else:\n",
    "        print('BinarySearch Error: -1')\n",
    "        print('i = ', i)\n",
    "        print('j = ', j)\n",
    "        return -1\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "def store_array_to_file (input_array_name, file_name, index_=False, header_=None):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Store Array to ' + file_name + '): ', ct)\n",
    "\n",
    "    df = pd.DataFrame(input_array_name)\n",
    "    df.to_csv(file_name, index=index_, header=header_)\n",
    "\n",
    "    '''\n",
    "    with open(file_name, 'w') as filehandle:\n",
    "        for element in input_array_name:\n",
    "            filehandle.write(f'{element}\\n')\n",
    "    '''\n",
    "\n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Store Array to ' + file_name + '): ', et)\n",
    "\n",
    "    return\n",
    "\n",
    "##########################################################################################\n",
    "def load_file_to_array (file_name, header_=None):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Load ' + file_name  + ' to Array): ', ct)\n",
    "\n",
    "    df = pd.read_csv(file_name, header=header_)\n",
    "    output_array_name = df.to_numpy()\n",
    "    \n",
    "    '''\n",
    "    output_array_name = []\n",
    "    with open(file_name, 'r') as filehandle:\n",
    "        for line in filehandle:\n",
    "            # Remove linebreak which is the last character of the string\n",
    "            curr_place = line[:-1]\n",
    "            # Add item to the list\n",
    "            output_array_name.append(curr_place)\n",
    "    '''    \n",
    "\n",
    "    '''\n",
    "    for index, row in df.iterrows():\n",
    "        new_line = df.loc[index , 0]\n",
    "        output_array_name.append(new_line)\n",
    "        if (index%1000000 == 0):\n",
    "                print('One New Milion Records loaded: ', index)\n",
    "    '''\n",
    "\n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Load ' + file_name  + ' to Array): ', et)\n",
    "    \n",
    "    return output_array_name\n",
    "\n",
    "##########################################################################################\n",
    "def store_array_to_file_2D (input_array_name, file_name):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Store Array 2D to ' + file_name + '): ', ct)\n",
    "\n",
    "    with open(file_name, \"w\") as filehandle:\n",
    "        json.dump(input_array_name, filehandle)\n",
    "    \n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Store Array 2D to ' + file_name + '): ', et)\n",
    "\n",
    "    return\n",
    "\n",
    "##########################################################################################\n",
    "def load_file_to_array_2D (file_name):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Load ' + file_name  + ' to Array 2D): ', ct)\n",
    "\n",
    "    with open(file_name) as filehandle:\n",
    "        output_array_name = json.load(filehandle)\n",
    "\n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Load ' + file_name  + ' to Array 2D): ', et)\n",
    "    \n",
    "    return output_array_name\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "def store_dict_to_file_INT (input_dict_name, file_name):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Store Dictionary to ' + file_name + '): ', ct)\n",
    "\n",
    "    filehandle = csv.writer(open(file_name, 'w'))\n",
    "    for key, val in input_dict_name.items():\n",
    "        filehandle.writerow([key, val])\n",
    "\n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Store Dictionary to ' + file_name + '): ', et)\n",
    "\n",
    "    return\n",
    "\n",
    "##########################################################################################\n",
    "def load_file_to_dict_INT (file_name):\n",
    "    ct = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "    print('start time (Load ' + file_name  + ' to Dictionary): ', ct)\n",
    "\n",
    "    filehandle = csv.reader(open(file_name, 'r'))\n",
    "    output_dict_name = {int(rows[0]):int(rows[1]) for rows in filehandle}\n",
    "\n",
    "    et = datetime.datetime.now() - ct\n",
    "    print('elapsed time (Load ' + file_name  + ' to Dictionary): ', et)\n",
    "    \n",
    "    return output_dict_name\n",
    "\n",
    "##########################################################################################\n",
    "def add_edge_info(node_1, node_2, edges_array, weight=1):\n",
    "    if (node_1 == node_2):\n",
    "        return\n",
    "\n",
    "    # make sure always we have n1 > n2:\n",
    "    if (node_1 < node_2):\n",
    "        n1 = node_2\n",
    "        n2 = node_1\n",
    "    else:\n",
    "        n1 = node_1\n",
    "        n2 = node_2\n",
    "\n",
    "    for i in range(weight):\n",
    "        edges_array[n1].append(n2)\n",
    "\n",
    "    return\n",
    "\n",
    "##########################################################################################\n",
    "def extract_payment_delegation_parts(address_raw, payment_cred, stake_address):\n",
    "    if (address_raw == ''):\n",
    "        #print(' - Error: address_raw is empty!')\n",
    "        return ['', '']\n",
    "\n",
    "    if (address_raw[2] == '8'): #Byron Address\n",
    "        if (payment_cred != ''):\n",
    "            print(' - Error: payment_cred in Byron Address is NOT empty!')\n",
    "            return ['', '']\n",
    "        if (stake_address != ''):\n",
    "            print(' - Error: stake_address in Byron Address is NOT empty!')\n",
    "            return ['', '']\n",
    "        payment_part    = address_raw\n",
    "        delegation_part = ''\n",
    "\n",
    "    else: #Shelley Address\n",
    "        if (payment_cred == ''):\n",
    "            print(' - Error: payment_cred in Shelley Address is empty!')\n",
    "            return ['', '']\n",
    "        payment_part    = payment_cred\n",
    "        delegation_part = stake_address\n",
    "\n",
    "    return [payment_part, delegation_part]\n",
    "\n",
    "##########################################################################################\n",
    "# Function which calculates the Gini index\n",
    "# Inputs: array with length equal to number of agents; each element in array represents the wealth of the agent\n",
    "# Outputs: gini index of the system\n",
    "def gini_index(inp_array):\n",
    "    array = np.array(inp_array)\n",
    "    array = array.astype(float)\n",
    "    array = array.flatten() #all values are treated equally, arrays must be 1d\n",
    "    if np.amin(array) < 0:\n",
    "        array -= np.amin(array) #values cannot be negative\n",
    "    array += 0.0000001 #values cannot be 0\n",
    "    array = np.sort(array) #values must be sorted\n",
    "    index = np.arange(1,array.shape[0]+1) #index per array element\n",
    "    n = array.shape[0] #number of array elements\n",
    "    return ((np.sum((2 * index - n  - 1) * array)) / (n * np.sum(array))) #Gini coefficient\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9457e2fe-b760-4eae-a04c-c655d7dfcca5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de58dae-0117-4fee-813c-3ee3af1474bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create List of all Addresses [raw_address_list, payment_address_list, and delegation_address_list]:\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "print('----------------------')\n",
    "\n",
    "\n",
    "# List of all addresses (from INPUTs and OUTPUTs)\n",
    "raw_address_list = []\n",
    "payment_address_list = []\n",
    "delegation_address_list = []\n",
    "\n",
    "\n",
    "\n",
    "CSV_FILES_NAME_FORMAT = BASE_ADDRESS + '/cardano_TXs_'\n",
    "NUMBER_OF_CSV_FILES = 6\n",
    "CSV_FILES_SUFFIX = '.csv'\n",
    "\n",
    "\n",
    "for i in range(1, NUMBER_OF_CSV_FILES + 1):\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "    file_name = CSV_FILES_NAME_FORMAT + str(i) + CSV_FILES_SUFFIX\n",
    "    df = pd.read_csv(file_name, delimiter='|')\n",
    "\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Load CSV File \" + file_name + \"): \", et_temp)\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        ##########################################################################################\n",
    "        #inputs_list = list( df.loc[index , 'INPUTs'].split(';') )\n",
    "        #for tx_input in inputs_list:\n",
    "        #    tx_input_UTXO_address = tx_input.split(',')[4]\n",
    "        #    payment_address_list.append(tx_input_UTXO_address)\n",
    "        ##########################################################################################\n",
    "        outputs_list = list( df.loc[index , 'OUTPUTs'].split(';') )\n",
    "        #TX_ID = df.loc[index , 'TX_ID']\n",
    "        for tx_output in outputs_list:\n",
    "            address_raw        = tx_output.split(',')[1]\n",
    "            address_has_script = tx_output.split(',')[4]\n",
    "            payment_cred       = tx_output.split(',')[5]\n",
    "            stake_address      = tx_output.split(',')[6]\n",
    "            [address_payment_part, address_delegation_part] = extract_payment_delegation_parts(address_raw, payment_cred, stake_address)\n",
    "            if (address_raw != ''):\n",
    "                raw_address_list.append(address_raw)\n",
    "            if (address_payment_part != ''):\n",
    "                payment_address_list.append(address_payment_part)\n",
    "            if (address_delegation_part != ''):\n",
    "                delegation_address_list.append(address_delegation_part)\n",
    "        ##########################################################################################\n",
    "\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Extract Addresses from INs/OUTs of CSV File \" + file_name + \"): \", et_temp)\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Create list of Addresses Array List in Python): \", et)\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116a0ab-d595-4a43-9dfb-6b6730779f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e9744-5295-465e-94f9-60ce9de65115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write \"raw_address_list/payment_address_list/delegation_address_list\" into a File:\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "# write a list into a file:\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "output_filename = BASE_ADDRESS + '/AddressListRaw__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "store_array_to_file (raw_address_list, output_filename)\n",
    "\n",
    "\n",
    "\n",
    "# write a list into a file:\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "output_filename = BASE_ADDRESS + '/AddressListPayment__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "store_array_to_file (payment_address_list, output_filename)\n",
    "\n",
    "\n",
    "\n",
    "# write a list into a file:\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "output_filename = BASE_ADDRESS + '/AddressListDelegation__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "store_array_to_file (delegation_address_list, output_filename)\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65eb8aef-fbea-4e2d-ba47-9308f9357b35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ba4b6f-c3d2-4091-83fa-7a279f62c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Linux (\"Sort\" and \"Remove Duplicate Addresses\" in raw_address_list/payment_address_list/delegation_address_list:\n",
    "\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "os.system('sort -k 1 -u /local/scratch/exported/blockchain_parsed/cardano_mostafa/AddressListRaw__Cardano_TXs_All__2023-02-28_143357.txt        > /local/scratch/exported/blockchain_parsed/cardano_mostafa/Unique_AddressesListRaw__Cardano_TXs_All__2023-02-28_143357.txt')\n",
    "os.system('sort -k 1 -u /local/scratch/exported/blockchain_parsed/cardano_mostafa/AddressListPayment__Cardano_TXs_All__2023-02-28_143953.txt    > /local/scratch/exported/blockchain_parsed/cardano_mostafa/Unique_AddressesListPayment__Cardano_TXs_All__2023-02-28_143953.txt')\n",
    "os.system('sort -k 1 -u /local/scratch/exported/blockchain_parsed/cardano_mostafa/AddressListDelegation__Cardano_TXs_All__2023-02-28_144415.txt > /local/scratch/exported/blockchain_parsed/cardano_mostafa/Unique_AddressesListDelegation__Cardano_TXs_All__2023-02-28_144415.txt')\n",
    "\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837d4452-5210-4763-975d-3a37010aa26c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d9d564-4b4b-43c1-adda-d2a2c5a718e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "start time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa/Unique_AddressesListRaw__Cardano_TXs_All__2023-02-28_143357.txt to Array):  2023-04-07 09:44:58.531741\n",
      "elapsed time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa/Unique_AddressesListRaw__Cardano_TXs_All__2023-02-28_143357.txt to Array):  0:00:46.270749\n",
      "Length of \"unique_raw_addresses\" = 40330345\n",
      "start time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa/Unique_AddressesListPayment__Cardano_TXs_All__2023-02-28_143953.txt to Array):  2023-04-07 09:45:44.802923\n",
      "elapsed time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa/Unique_AddressesListPayment__Cardano_TXs_All__2023-02-28_143953.txt to Array):  0:00:35.430624\n",
      "Length of \"unique_payment_addresses\" = 40324960\n",
      "start time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa/Unique_AddressesListDelegation__Cardano_TXs_All__2023-02-28_144415.txt to Array):  2023-04-07 09:46:20.234022\n",
      "elapsed time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa/Unique_AddressesListDelegation__Cardano_TXs_All__2023-02-28_144415.txt to Array):  0:00:02.752679\n",
      "Length of \"unique_delegation_addresses\" = 3868049\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Read (\"sorted\" \"unique\" array_list) [raw_address_list/payment_address_list/delegation_address_list] from file:\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "\n",
    "file_name = BASE_ADDRESS + '/Unique_AddressesListRaw__Cardano_TXs_All__2023-02-28_143357.txt'\n",
    "unique_raw_addresses = load_file_to_array (file_name)\n",
    "print('Length of \\\"unique_raw_addresses\\\" = ' + str(len(unique_raw_addresses)))\n",
    "\n",
    "\n",
    "file_name = BASE_ADDRESS + '/Unique_AddressesListPayment__Cardano_TXs_All__2023-02-28_143953.txt'\n",
    "unique_payment_addresses = load_file_to_array (file_name)\n",
    "print('Length of \\\"unique_payment_addresses\\\" = ' + str(len(unique_payment_addresses)))\n",
    "\n",
    "\n",
    "file_name = BASE_ADDRESS + '/Unique_AddressesListDelegation__Cardano_TXs_All__2023-02-28_144415.txt'\n",
    "unique_delegation_addresses = load_file_to_array (file_name)\n",
    "print('Length of \\\"unique_delegation_addresses\\\" = ' + str(len(unique_delegation_addresses)))\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53011055-f453-42c8-a9e4-b9a4d94479df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413be459-eb91-4769-8e3e-03b89b511db9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40330345/40330345 [00:21<00:00, 1853957.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "byron_count   =  11282384\n",
      "shelley_count =  29047961\n",
      "----------------------\n",
      "done!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# count Byron and Shelley addresses:\n",
    "\n",
    "byron_count = 0\n",
    "shelley_count = 0\n",
    "\n",
    "for i in tqdm(range(len(unique_raw_addresses))):\n",
    "    if (unique_raw_addresses[i][0][2] == '8'): #Byron Address\n",
    "        byron_count = byron_count+1\n",
    "    else: #Shelley Address\n",
    "        shelley_count = shelley_count+1\n",
    "\n",
    "print('byron_count   = ', byron_count)\n",
    "print('shelley_count = ', shelley_count)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6087ea8e-08c1-4300-ac24-bf479e9e5e13",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0710626d-85bc-462d-9748-edb802beb84e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Find Number of new Byron, Shelley, and Stake Addresses VS \"Time\":\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "file_name = BASE_ADDRESS + '/cardano_epochs_MinTXID_CardanoAllTXs.csv'\n",
    "df = pd.read_csv(file_name, delimiter='|')\n",
    "#df['EPOCH_NO']\n",
    "#df['MIN_TX_ID']\n",
    "#df['MIN_TIME_UTC']\n",
    "first_TX_IDs_in_epoch_array = df['MIN_TX_ID'].to_numpy()\n",
    "current_epoch = -1\n",
    "\n",
    "\n",
    "\n",
    "place_holder = 999999999999\n",
    "raw_addresses_epoch_array             = np.array([place_holder] * len(unique_raw_addresses))\n",
    "Byron_payment_addresses_epoch_array   = np.array([place_holder] * len(unique_payment_addresses))\n",
    "Shelley_payment_addresses_epoch_array = np.array([place_holder] * len(unique_payment_addresses))\n",
    "delegation_addresses_epoch_array      = np.array([place_holder] * len(unique_delegation_addresses))\n",
    "\n",
    "\n",
    "\n",
    "CSV_FILES_NAME_FORMAT = BASE_ADDRESS + '/cardano_TXs_'\n",
    "NUMBER_OF_CSV_FILES = 6\n",
    "CSV_FILES_SUFFIX = '.csv'\n",
    "\n",
    "for i in range(1, NUMBER_OF_CSV_FILES + 1):\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "    file_name = CSV_FILES_NAME_FORMAT + str(i) + CSV_FILES_SUFFIX\n",
    "    df = pd.read_csv(file_name, delimiter='|')\n",
    "\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Load CSV File \" + file_name + \"): \", et_temp)\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        ##########################################################################################\n",
    "        TX_ID = df.loc[index, 'TX_ID']\n",
    "        if(TX_ID == first_TX_IDs_in_epoch_array[current_epoch + 2]):\n",
    "            current_epoch = current_epoch + 1\n",
    "        ##########################################################################################\n",
    "        #inputs_list = list( df.loc[index , 'INPUTs'].split(';') )\n",
    "        #for tx_input in inputs_list:\n",
    "        #    tx_input_UTXO_address = tx_input.split(',')[4]\n",
    "        #    payment_address_list.append(tx_input_UTXO_address)\n",
    "        ##########################################################################################\n",
    "        outputs_list = list( df.loc[index , 'OUTPUTs'].split(';') )\n",
    "        #TX_ID = df.loc[index , 'TX_ID']\n",
    "        for tx_output in outputs_list:\n",
    "            address_raw        = tx_output.split(',')[1]\n",
    "            address_has_script = tx_output.split(',')[4]\n",
    "            payment_cred       = tx_output.split(',')[5]\n",
    "            stake_address      = tx_output.split(',')[6]\n",
    "            [address_payment_part, address_delegation_part] = extract_payment_delegation_parts(address_raw, payment_cred, stake_address)\n",
    "            if (address_raw != ''): \n",
    "                addr_position = BinarySearch(unique_raw_addresses, address_raw)\n",
    "                if(raw_addresses_epoch_array[addr_position] == place_holder):\n",
    "                    raw_addresses_epoch_array[addr_position] = current_epoch\n",
    "\n",
    "            if (address_payment_part != ''): \n",
    "                if (address_raw[2] == '8'): #Byron Address\n",
    "                    addr_position = BinarySearch(unique_payment_addresses, address_payment_part)\n",
    "                    if(Byron_payment_addresses_epoch_array[addr_position] == place_holder):\n",
    "                        Byron_payment_addresses_epoch_array[addr_position] = current_epoch\n",
    "                else: #Shelley Address\n",
    "                    addr_position = BinarySearch(unique_payment_addresses, address_payment_part)\n",
    "                    if(Shelley_payment_addresses_epoch_array[addr_position] == place_holder):\n",
    "                        Shelley_payment_addresses_epoch_array[addr_position] = current_epoch\n",
    "\n",
    "            if(address_delegation_part != ''):\n",
    "                addr_position = BinarySearch(unique_delegation_addresses, address_delegation_part)\n",
    "                if(delegation_addresses_epoch_array[addr_position] == place_holder):\n",
    "                    delegation_addresses_epoch_array[addr_position] = current_epoch\n",
    "\n",
    "        ##########################################################################################\n",
    "\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Detect Byron and Shelley Addresses from INs/OUTs of CSV File \" + file_name + \"): \", et_temp)\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Detect Byron and Shelley Addresses): \", et)\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1969f24f-9062-4ab2-985a-681d1afe65e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c1a2eb-4ccb-482d-b1d7-cc37279d939d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/Store \"raw_addresses_epoch_array\"              from/into file:\n",
    "#            \"Byron_payment_addresses_epoch_array\", \n",
    "#            \"Shelley_payment_addresses_epoch_array\", \n",
    "#            \"delegation_addresses_epoch_array\"\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "      \n",
    "\n",
    "# Store \"raw_addresses_epoch_array\",              into file:\n",
    "#       \"Byron_payment_addresses_epoch_array\", \n",
    "#       \"Shelley_payment_addresses_epoch_array\", \n",
    "#       \"delegation_addresses_epoch_array\"\n",
    "'''\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "\n",
    "output_filename = BASE_ADDRESS + '/epochArray_rawAddresses__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "print('output_filename = ', output_filename)\n",
    "store_array_to_file(raw_addresses_epoch_array, output_filename)\n",
    "\n",
    "output_filename = BASE_ADDRESS + '/epochArray_ByronAddresses__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "print('output_filename = ', output_filename)\n",
    "store_array_to_file(Byron_payment_addresses_epoch_array, output_filename)\n",
    "\n",
    "output_filename = BASE_ADDRESS + '/epochArray_ShelleyAddresses__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "print('output_filename = ', output_filename)\n",
    "store_array_to_file(Shelley_payment_addresses_epoch_array, output_filename)\n",
    "\n",
    "output_filename = BASE_ADDRESS + '/epochArray_delegationAddresses__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "print('output_filename = ', output_filename)\n",
    "store_array_to_file(delegation_addresses_epoch_array, output_filename)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Load  \"raw_addresses_epoch_array\",              from file:\n",
    "#       \"Byron_payment_addresses_epoch_array\", \n",
    "#       \"Shelley_payment_addresses_epoch_array\", \n",
    "#       \"delegation_addresses_epoch_array\"\n",
    "'''\n",
    "file_name = BASE_ADDRESS + '/epochArray_rawAddresses__Cardano_TXs_All__?????????.txt'\n",
    "raw_addresses_epoch_array             = load_file_to_array(file_name)\n",
    "\n",
    "file_name = BASE_ADDRESS + '/epochArray_ByronAddresses__Cardano_TXs_All__?????????.txt'\n",
    "Byron_payment_addresses_epoch_array   = load_file_to_array(file_name)\n",
    "\n",
    "file_name = BASE_ADDRESS + '/epochArray_ShelleyAddresses__Cardano_TXs_All__?????????.txt'\n",
    "Shelley_payment_addresses_epoch_array = load_file_to_array(file_name)\n",
    "\n",
    "file_name = BASE_ADDRESS + '/epochArray_delegationAddresses__Cardano_TXs_All__?????????.txt'\n",
    "delegation_addresses_epoch_array      = load_file_to_array(file_name)\n",
    "'''\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea36e37-328f-451d-af92-8979e4717681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e92b65-0ce0-4d4a-a308-d72491a82543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate \"Parents_Array\" based on Heuristics:\n",
    "\n",
    "\n",
    "def generate_parents_array(queue_):\n",
    "    # read input queue arguments\n",
    "    in_args = queue_.get()\n",
    "\n",
    "    csv_file_name = in_args[0]\n",
    "    Heuristic_1   = in_args[1]\n",
    "    Heuristic_2   = in_args[2]\n",
    "    Heuristic_3   = in_args[3]\n",
    "\n",
    "    csv_file_basename = os.path.basename(csv_file_name)\n",
    "\n",
    "    # print current process identity\n",
    "    str_current_proc = 'current_process()._identity[0] ' + '(' + csv_file_basename + ')' + ' = ' + str(current_process()._identity[0])\n",
    "    print(str_current_proc)\n",
    "\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "\n",
    "    # Create SparkSession \n",
    "    spark = SparkSession.builder \\\n",
    "                     .master(\"local[1]\") \\\n",
    "                     .appName(\"Mostafa_SparkTest_1\") \\\n",
    "                     .config('spark.driver.maxResultSize', '70g') \\\n",
    "                     .config('spark.executor.cores', 4) \\\n",
    "                     .config('spark.executor.memory', '30g') \\\n",
    "                     .config('spark.driver.memory', '30g') \\\n",
    "                     .config('spark.memory.offHeap.enabled', True) \\\n",
    "                     .config('spark.memory.offHeap.size', '40g') \\\n",
    "                     .getOrCreate() \n",
    "\n",
    "    #df = pd.read_csv(csv_file_name, delimiter='|')\n",
    "    df = spark.read.option(\"delimiter\", \"|\").csv(csv_file_name, inferSchema=True, header=True)\n",
    "\n",
    "\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Load CSV File \" + csv_file_name + \"): \", et_temp)\n",
    "\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "\n",
    "    # Initialize parents_array:\n",
    "    parents_array = np.array([0] * unique_payment_addresses_len)\n",
    "    for i in range(unique_payment_addresses_len):\n",
    "        parents_array[i] = i    \n",
    "\n",
    "\n",
    "    # Initialize graph_edges_array:\n",
    "    graph_edges_array = [[] for _ in range(unique_payment_addresses_len)]\n",
    "\n",
    "\n",
    "    #for index, row in df.iterrows():\n",
    "    #position=int(str(csv_file_basename)[12:13]\n",
    "    #for row in tqdm(df.collect(), desc=f'Process {csv_file_basename}', position=current._identity[0] - 1, leave=True):\n",
    "    #for row in tqdm(df.collect(), desc=f'Process {csv_file_basename}'):\n",
    "    for row in df.collect():\n",
    "        #inputs_list = list( df.loc[index , 'INPUTs'].split(';') )\n",
    "        #outputs_list = list( df.loc[index , 'OUTPUTs'].split(';') )\n",
    "        inputs_list  = list( row['INPUTs'].split(';') )\n",
    "        outputs_list = list( row['OUTPUTs'].split(';') )\n",
    "        #TX_ID        = row['TX_ID']\n",
    "\n",
    "        ##########################################################################################\n",
    "        #Heuristic 1:\n",
    "        if (Heuristic_1 == True):\n",
    "            nonSC_addr_positions = []\n",
    "\n",
    "            for i in range(0, len(inputs_list)):\n",
    "                address_has_script = inputs_list[i].split(',')[7]\n",
    "                if (address_has_script == 'f'): # non-Smart Contract Address\n",
    "                    address_raw   = inputs_list[i].split(',')[4]\n",
    "                    payment_cred  = inputs_list[i].split(',')[8]\n",
    "                    stake_address = inputs_list[i].split(',')[9]\n",
    "                    [address_payment_part, address_delegation_part] = extract_payment_delegation_parts(address_raw, payment_cred, stake_address)\n",
    "                    if (address_payment_part != ''):\n",
    "                        address_position = BinarySearch(unique_payment_addresses, address_payment_part)\n",
    "                        nonSC_addr_positions.append(address_position) \n",
    "\n",
    "            for i in range(1, len(nonSC_addr_positions)):\n",
    "                link_address(nonSC_addr_positions[0], nonSC_addr_positions[i], parents_array)                \n",
    "                for j in range(0, i):\n",
    "                    # find and store corresponding \"edges\" for Graph:\n",
    "                    add_edge_info(node_1=nonSC_addr_positions[i], node_2=nonSC_addr_positions[j], edges_array=graph_edges_array, weight=1)\n",
    "\n",
    "\n",
    "        ##########################################################################################\n",
    "        #Heuristic 2 (link input[0] to outputs with values smaller than all inputs):\n",
    "        if (Heuristic_2 == True):\n",
    "            smallest_intput_UTXO_value = int(inputs_list[0].split(',')[6])\n",
    "            for i in range(1, len(inputs_list)):\n",
    "                smallest_intput_UTXO_value = min(smallest_intput_UTXO_value, int(inputs_list[i].split(',')[6]))\n",
    "\n",
    "            for i in range(0, len(outputs_list)):\n",
    "                tx_output_UTXO_value = int(outputs_list[i].split(',')[3])\n",
    "\n",
    "                if (tx_output_UTXO_value < smallest_intput_UTXO_value):\n",
    "                    first_input_UTXO_address = inputs_list[0].split(',')[4]\n",
    "                    #addr_position_1 = np.where(unique_payment_addresses == first_input_UTXO_address)[0][0]\n",
    "                    addr_position_1 = BinarySearch(unique_payment_addresses, first_input_UTXO_address)\n",
    "\n",
    "                    tx_output_UTXO_address = outputs_list[i].split(',')[1]\n",
    "                    #addr_position_2 = np.where(unique_payment_addresses == tx_output_UTXO_address)[0][0]\n",
    "                    addr_position_2 = BinarySearch(unique_payment_addresses, tx_output_UTXO_address)\n",
    "\n",
    "                    link_address(addr_position_1, addr_position_2, parents_array)\n",
    "        \n",
    "                    # find and store corresponding \"edges\" for Graph:\n",
    "                    add_edge_info(node_1=addr_position_1, node_2=addr_position_2, edges_array=graph_edges_array, weight=1)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    spark.stop()\n",
    "\n",
    "\n",
    "    # Resolve parents array\n",
    "    resolveAll (parents_array)\n",
    "\n",
    "    # Put file address of parents_array in queue\n",
    "    ct_file = datetime.datetime.now()\n",
    "    curr_timestamp = str(ct_file)[0:10] + '_' + str(ct_file)[11:13] + str(ct_file)[14:16] + str(ct_file)[17:26]\n",
    "\n",
    "    output_parents_filename = TEMP_ADDRESS + '/parentsList_temp__' + csv_file_basename + '__' + curr_timestamp + '.txt'\n",
    "    store_array_to_file   (parents_array, output_parents_filename)\n",
    "\n",
    "    output_graghEdges_filename = TEMP_ADDRESS + '/graphEdgesList_temp__' + csv_file_basename + '__' + curr_timestamp + '.txt'\n",
    "    store_array_to_file_2D(graph_edges_array, output_graghEdges_filename)\n",
    "\n",
    "    queue_.put([output_parents_filename, output_graghEdges_filename])\n",
    "\n",
    "\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Link Addresses with Heuristics in CSV File \" + csv_file_basename + \"): \", et_temp)\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a99347a-cdd8-4188-9b52-7e945d7b6f51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6571dec-e2fa-4b40-8073-90c379627f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate \"balances_array\" [Sequential Computation]:\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "\n",
    "CSV_FILES_NAME_FORMAT = BASE_ADDRESS + '/cardano_TXs_'\n",
    "NUMBER_OF_CSV_FILES = 6\n",
    "CSV_FILES_SUFFIX = '.csv'\n",
    "\n",
    "\n",
    "# Initialize balances_array:\n",
    "balances_array = np.array([0] * unique_payment_addresses_len)\n",
    "for i in range(unique_payment_addresses_len):\n",
    "    balances_array[i] = 0 \n",
    "\n",
    "\n",
    "\n",
    "gini_array = [0]\n",
    "gini_sample_id = 200000\n",
    "\n",
    "\n",
    "for i in range(1, NUMBER_OF_CSV_FILES + 1):\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "    file_name = CSV_FILES_NAME_FORMAT + str(i) + CSV_FILES_SUFFIX\n",
    "    df = pd.read_csv(file_name, delimiter='|')\n",
    "\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Load CSV File \" + file_name + \"): \", et_temp)\n",
    "\n",
    "\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        ##########################################################################################\n",
    "        TX_ID = df.loc[index , 'TX_ID']\n",
    "        inputs_list = list( df.loc[index , 'INPUTs'].split(';') )\n",
    "        outputs_list = list( df.loc[index , 'OUTPUTs'].split(';') )\n",
    "\n",
    "        #################################################################\n",
    "        # Calculate \"Gini Index\":\n",
    "        if (int(TX_ID) > gini_sample_id):\n",
    "            gini_array_indx = int(gini_sample_id/200000)\n",
    "            balances_array_no_zeros = balances_array[balances_array != 0]\n",
    "            gini_array.append(gini_index(balances_array_no_zeros))\n",
    "            if (TX_ID < 2000002):\n",
    "                print('TX_ID = ', TX_ID, '  |  gini_array [', gini_array_indx, '] = ', gini_array[gini_array_indx])\n",
    "            gini_sample_id = gini_sample_id + 200000\n",
    "\n",
    "        #################################################################\n",
    "        for i in range(0, len(inputs_list)):\n",
    "            address_has_script = inputs_list[i].split(',')[7]\n",
    "            if (address_has_script == 'f'): # non-Smart Contract Address\n",
    "                address_raw   = inputs_list[i].split(',')[4]\n",
    "                payment_cred  = inputs_list[i].split(',')[8]\n",
    "                stake_address = inputs_list[i].split(',')[9]\n",
    "                [address_payment_part, address_delegation_part] = extract_payment_delegation_parts(address_raw, payment_cred, stake_address)\n",
    "                if (address_payment_part != ''):\n",
    "                    address_position = BinarySearch(unique_payment_addresses, address_payment_part)\n",
    "                    UTXO_value = inputs_list[i].split(',')[6]\n",
    "                    balances_array[address_position] = balances_array[address_position] - int(UTXO_value)\n",
    "        #################################################################\n",
    "        for i in range(0, len(outputs_list)):\n",
    "            address_has_script = outputs_list[i].split(',')[4]\n",
    "            if (address_has_script == 'f'): # non-Smart Contract Address\n",
    "                address_raw   = outputs_list[i].split(',')[1]\n",
    "                payment_cred  = outputs_list[i].split(',')[5]\n",
    "                stake_address = outputs_list[i].split(',')[6]\n",
    "                [address_payment_part, address_delegation_part] = extract_payment_delegation_parts(address_raw, payment_cred, stake_address)\n",
    "                if (address_payment_part != ''):\n",
    "                    address_position = BinarySearch(unique_payment_addresses, address_payment_part)\n",
    "                    UTXO_value = outputs_list[i].split(',')[3]\n",
    "                    balances_array[address_position] = balances_array[address_position] + int(UTXO_value)\n",
    "        #################################################################\n",
    "\n",
    "\n",
    "    ##########################################################################################\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Load CSV File \" + file_name + \"): \", et_temp)\n",
    "    ##########################################################################################\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4db16f1-d784-4853-8ef2-2a55834db6c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa88de23-644f-4cd0-a5c8-4ff4f1d1ae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store \"balances_array\" into file:\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "output_filename = BASE_ADDRESS + '/balancesList_paymentAddresses_noSC__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "print('output_filename = ', output_filename)\n",
    "\n",
    "store_array_to_file (balances_array, output_filename)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2c3ee7-6bea-4c49-9d90-c599f1021e18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b5d2dd-00d9-43e7-a6ef-45585a8be196",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store \"gini_array\" into file:\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "output_filename = BASE_ADDRESS + '/giniArray_noZeros__paymentAddresses_noSC__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "print('output_filename = ', output_filename)\n",
    "\n",
    "store_array_to_file (gini_array, output_filename)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c996338-8840-4cdf-89f8-40e3aaa4fc09",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "362363a9-6439-4dd4-8e7c-c76e364db2b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristic 2 (link \"Shelley Addresses\" with the same \"address_delegation_part\"):\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "print('----------------------')\n",
    "\n",
    "\n",
    "# Initialize stake_delegation_array (For every \"stake_address\", this array shows which \"payment_addresses\" are delegated to it):\n",
    "stake_delegation_array = [[] for _ in range(unique_delegation_addresses_len)]\n",
    "\n",
    "\n",
    "CSV_FILES_NAME_FORMAT = BASE_ADDRESS + '/cardano_TXs_'\n",
    "NUMBER_OF_CSV_FILES = 6\n",
    "CSV_FILES_SUFFIX = '.csv'\n",
    "\n",
    "\n",
    "for i in range(1, NUMBER_OF_CSV_FILES + 1):\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "    file_name = CSV_FILES_NAME_FORMAT + str(i) + CSV_FILES_SUFFIX\n",
    "    df = pd.read_csv(file_name, delimiter='|')\n",
    "\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Load CSV File \" + file_name + \"): \", et_temp)\n",
    "\n",
    "    ct_temp = datetime.datetime.now()\n",
    "\n",
    "    for index, row in tqdm(df.iterrows()):\n",
    "        ##########################################################################################\n",
    "        #inputs_list = list( df.loc[index , 'INPUTs'].split(';') )\n",
    "        #for tx_input in inputs_list:\n",
    "        #    tx_input_UTXO_address = tx_input.split(',')[4]\n",
    "        #    payment_address_list.append(tx_input_UTXO_address)\n",
    "        ##########################################################################################\n",
    "        outputs_list = list( df.loc[index , 'OUTPUTs'].split(';') )\n",
    "        #TX_ID = df.loc[index , 'TX_ID']\n",
    "        for tx_output in outputs_list:\n",
    "            address_raw        = tx_output.split(',')[1]\n",
    "            address_has_script = tx_output.split(',')[4]\n",
    "            payment_cred       = tx_output.split(',')[5]\n",
    "            stake_address      = tx_output.split(',')[6]\n",
    "            [address_payment_part, address_delegation_part] = extract_payment_delegation_parts(address_raw, payment_cred, stake_address)\n",
    "            if (address_payment_part != '' and address_delegation_part != ''):\n",
    "                indx1 = BinarySearch(unique_delegation_addresses, address_delegation_part)\n",
    "                indx2 = BinarySearch(unique_payment_addresses, address_payment_part)\n",
    "                stake_delegation_array[indx1].append(indx2)\n",
    "        ##########################################################################################\n",
    "\n",
    "    et_temp = datetime.datetime.now() - ct_temp\n",
    "    print(\"elapsed time (Extract stake delegations from CSV File \" + file_name + \"): \", et_temp)\n",
    "\n",
    "\n",
    "\n",
    "# unique sort the \"stake_delegation_array\":\n",
    "for i in tqdm(range(len(stake_delegation_array))):\n",
    "    stake_delegation_array[i] = sorted(set(stake_delegation_array[i]))\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Heuristic2: find \\\"Shelley Addresses\\\" with the same \\\"address_delegation_part\\\"): \", et)\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a7f1e5-3c96-45b7-9001-d0d8bdce335d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ddd742-a02f-4f83-895c-dd4a1d30568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load/Store \"stake_delegation_array\" from/into file:\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "\n",
    "# Store \"stake_delegation_array\" into file:\n",
    "'''\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "output_filename = BASE_ADDRESS + '/stakeDelegationArray__Heuristic2__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "print('output_filename = ', output_filename)\n",
    "store_array_to_file_2D(stake_delegation_array, output_filename)\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Load stake_delegation_array from file:\n",
    "'''\n",
    "file_name = BASE_ADDRESS + '/stakeDelegationArray__Heuristic2__Cardano_TXs_All__2023-03-26_043620.txt'\n",
    "stake_delegation_array = load_file_to_array_2D(file_name)\n",
    "'''\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b85d07b-6dc0-4c5c-8e87-419adcb353f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650c250-8d7a-456e-bd13-8f28a613e878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Fill \"parents_heur2_array\" (based on \"stake_delegation_array\"):\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "ct = datetime.datetime.now()\n",
    "\n",
    "\n",
    "# Initialize parents_array:\n",
    "parents_heur2_array = np.array([0] * unique_payment_addresses_len)\n",
    "for i in range(unique_payment_addresses_len):\n",
    "    parents_heur2_array[i] = i\n",
    "\n",
    "\n",
    "# link \"Shelley Addresses\" with the same \"address_delegation_part\":\n",
    "for i in tqdm(range(len(stake_delegation_array))):\n",
    "    for j in range(1, len(stake_delegation_array[i])):\n",
    "        link_address(stake_delegation_array[i][0], stake_delegation_array[i][j], parents_heur2_array)\n",
    "\n",
    "\n",
    "# Resolve parents array\n",
    "resolveAll (parents_heur2_array)\n",
    "\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Create and Fill \\\"heur2_parents_array\\\"): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977d355-cef5-4ccd-878c-fcae1b38cfc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90ddc1d-7011-4012-937e-ddc8685629de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Fill \"Parents_\" arrays (related to \"Heuristic1\"):\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "if __name__ == \"__main__\":  # confirms that the code is under main function\n",
    "    q1 = Queue()\n",
    "    q2 = Queue()\n",
    "    q3 = Queue()\n",
    "    q4 = Queue()\n",
    "    q5 = Queue()\n",
    "    q6 = Queue()\n",
    "\n",
    "    q1.put([BASE_ADDRESS + '/cardano_TXs_1.csv', True, False, False])\n",
    "    q2.put([BASE_ADDRESS + '/cardano_TXs_2.csv', True, False, False])\n",
    "    q3.put([BASE_ADDRESS + '/cardano_TXs_3.csv', True, False, False])\n",
    "    q4.put([BASE_ADDRESS + '/cardano_TXs_4.csv', True, False, False])\n",
    "    q5.put([BASE_ADDRESS + '/cardano_TXs_5.csv', True, False, False])\n",
    "    q6.put([BASE_ADDRESS + '/cardano_TXs_6.csv', True, False, False])\n",
    "\n",
    "    # Create Processes:\n",
    "    p1 = mp.Process(target=generate_parents_array, args=(q1,))\n",
    "    p2 = mp.Process(target=generate_parents_array, args=(q2,))\n",
    "    p3 = mp.Process(target=generate_parents_array, args=(q3,))\n",
    "    p4 = mp.Process(target=generate_parents_array, args=(q4,))\n",
    "    p5 = mp.Process(target=generate_parents_array, args=(q5,))\n",
    "    p6 = mp.Process(target=generate_parents_array, args=(q6,))\n",
    "\n",
    "    # Start Processes:\n",
    "    p1.start()\n",
    "    p2.start()\n",
    "    p3.start()\n",
    "    p4.start()\n",
    "    p5.start()\n",
    "    p6.start()\n",
    "\n",
    "    # Wait for Processes to finish:\n",
    "    p1.join()\n",
    "    p2.join()\n",
    "    p3.join()\n",
    "    p4.join()\n",
    "    p5.join()\n",
    "    p6.join()\n",
    "\n",
    "    print('----------------------')\n",
    "    output_filename_1 = q1.get()\n",
    "    parents_1    = load_file_to_array   (output_filename_1[0])\n",
    "    graghEdges_1 = load_file_to_array_2D(output_filename_1[1])\n",
    "    print('parents_1 and graghEdges_1 loaded!')\n",
    "\n",
    "    output_filename_2 = q2.get()\n",
    "    parents_2    = load_file_to_array   (output_filename_2[0])\n",
    "    graghEdges_2 = load_file_to_array_2D(output_filename_2[1])\n",
    "    print('parents_2 and graghEdges_2 loaded!')\n",
    "\n",
    "    output_filename_3 = q3.get()\n",
    "    parents_3    = load_file_to_array   (output_filename_3[0])\n",
    "    graghEdges_3 = load_file_to_array_2D(output_filename_3[1])\n",
    "    print('parents_3 and graghEdges_3 loaded!')\n",
    "\n",
    "    output_filename_4 = q4.get()\n",
    "    parents_4    = load_file_to_array   (output_filename_4[0])\n",
    "    graghEdges_4 = load_file_to_array_2D(output_filename_4[1])\n",
    "    print('parents_4 and graghEdges_4 loaded!')\n",
    "\n",
    "    output_filename_5 = q5.get()\n",
    "    parents_5    = load_file_to_array   (output_filename_5[0])\n",
    "    graghEdges_5 = load_file_to_array_2D(output_filename_5[1])\n",
    "    print('parents_5 and graghEdges_5 loaded!')\n",
    "\n",
    "    output_filename_6 = q6.get()\n",
    "    parents_6    = load_file_to_array   (output_filename_6[0])\n",
    "    graghEdges_6 = load_file_to_array_2D(output_filename_6[1])\n",
    "    print('parents_6 and graghEdges_6 loaded!')\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Fill Parents_Arrays with Heuristics for all CSV Files): \", et)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e81bebf-bd4b-462e-ba0c-15a4330b2763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a6d22a-33ef-4b39-a8b1-92f4e58c5b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Fill \"Parents_Merged Arrays\":\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "##########################################################################################\n",
    "# Initialize parents array:\n",
    "parents_merged = np.array([[0]] * unique_payment_addresses_len)\n",
    "for i in range(unique_payment_addresses_len):\n",
    "    parents_merged[i] = i\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# parents_merged = \"parents_1 + parents_2 + parents_3 + parents_4 + parents_5 + parents_6\":\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "resolveAll (parents_1)\n",
    "print('parents_1[] resolved!')\n",
    "\n",
    "resolveAll (parents_2)\n",
    "print('parents_2[] resolved!')\n",
    "\n",
    "resolveAll (parents_3)\n",
    "print('parents_3[] resolved!')\n",
    "\n",
    "resolveAll (parents_4)\n",
    "print('parents_4[] resolved!')\n",
    "\n",
    "resolveAll (parents_5)\n",
    "print('parents_5[] resolved!')\n",
    "\n",
    "resolveAll (parents_6)\n",
    "print('parents_6[] resolved!')\n",
    "'''\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "merge_parents(parents_1, parents_merged)\n",
    "print('parents_1[] merged!')\n",
    "\n",
    "merge_parents(parents_2, parents_merged)\n",
    "print('parents_2[] merged!')\n",
    "\n",
    "merge_parents(parents_3, parents_merged)\n",
    "print('parents_3[] merged!')\n",
    "\n",
    "merge_parents(parents_4, parents_merged)\n",
    "print('parents_4[] merged!')\n",
    "\n",
    "merge_parents(parents_5, parents_merged)\n",
    "print('parents_5[] merged!')\n",
    "\n",
    "merge_parents(parents_6, parents_merged)\n",
    "print('parents_6[] merged!')\n",
    "'''\n",
    "\n",
    "##########################################################################################\n",
    "# parents_merged = \"parents_heur2_array\":\n",
    "\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "resolveAll (parents_heur2_array)\n",
    "print('parents_heur2_array resolved!')\n",
    "'''\n",
    "\n",
    "'''\n",
    "print('----------------------')\n",
    "\n",
    "merge_parents(parents_heur2_array, parents_merged)\n",
    "print('parents_heur2_array merged!')\n",
    "'''\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "# parents_merged =   \"parents_heur2_array\":\n",
    "#                  + \"parents_1 + parents_2 + parents_3 + parents_4 + parents_5 + parents_6\":\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# Load parents_merged from file:\n",
    "file_name = BASE_ADDRESS + '/parentsList_Heuristic1noSC__Cardano_TXs_All__2023-02-25_223712.txt'\n",
    "parents_heur1_array = load_file_to_array (file_name)\n",
    "\n",
    "file_name = BASE_ADDRESS + '/parentsList_Heuristic2__Cardano_TXs_All__2023-03-26_105842.txt'\n",
    "parents_heur2_array = load_file_to_array (file_name)\n",
    "\n",
    "'''\n",
    "resolveAll (parents_heur1_array)\n",
    "print('parents_heur1_array resolved!')\n",
    "\n",
    "resolveAll (parents_heur2_array)\n",
    "print('parents_heur2_array resolved!')\n",
    "'''\n",
    "\n",
    "merge_parents(parents_heur1_array, parents_merged)\n",
    "print('parents_heur1_array merged!')\n",
    "\n",
    "merge_parents(parents_heur2_array, parents_merged)\n",
    "print('parents_heur2_array merged!')\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "\n",
    "resolveAll (parents_merged)\n",
    "print('parents_merged[] resolved!')\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Fill Parents_Merged Array): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27ccbca-3a4e-46e6-8ef3-98e122d51be3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f2137f-66e8-4cfe-905f-31fe9775f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store parents_merged into file:\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "\n",
    "#output_filename = BASE_ADDRESS + '/parentsList_Heuristic1noSC__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "#output_filename = BASE_ADDRESS + '/parentsList_Heuristic2__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "output_filename = BASE_ADDRESS + '/parentsList_Heuristic1noSC_AND_Heuristic2__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "\n",
    "\n",
    "\n",
    "print('output_filename = ', output_filename)\n",
    "store_array_to_file (parents_merged, output_filename)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0c389b6-5e7d-4d4f-9fac-e45a23e74538",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86df8677-b460-4037-a198-3ae6377939fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and Fill \"Clustering Array\":\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "\n",
    "clustering_array = np.array([0] * unique_payment_addresses_len)\n",
    "\n",
    "num_of_clusters = remapClusterIds (parents_merged, clustering_array)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('Length of \\\"clustering_array\\\" = ', len(clustering_array))\n",
    "print('Number of Clusters           = '  , len(np.unique(clustering_array)))\n",
    "print('Number of Clusters           = '  , max(clustering_array)+1)\n",
    "print('Number of Clusters           = '  , num_of_clusters)\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "print('clustering_array = ', clustering_array)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Fill Clustering Array with Heuristics): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f18a7d-b0db-4741-9c60-f86d08b6ecf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124061a6-bc60-4ece-b98d-4414d95cc1fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------\n",
      "start time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa/clusteringArrayList_Heuristic1noSC_AND_Heuristic2__Cardano_TXs_All__2023-03-26_141212.txt to Array):  2023-04-07 11:23:09.755594\n",
      "elapsed time (Load /local/scratch/exported/blockchain_parsed/cardano_mostafa/clusteringArrayList_Heuristic1noSC_AND_Heuristic2__Cardano_TXs_All__2023-03-26_141212.txt to Array):  0:00:02.532619\n",
      "----------------------\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "# Store/Load clustering_array into file:\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "\n",
    "\n",
    "# Store clustering_array[] into file:\n",
    "'''\n",
    "#output_filename = BASE_ADDRESS + '/clusteringArrayList_Heuristic1noSC__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "#output_filename = BASE_ADDRESS + '/clusteringArrayList_Heuristic2__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "output_filename = BASE_ADDRESS + '/clusteringArrayList_Heuristic1noSC_AND_Heuristic2__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "\n",
    "print('output_filename = ', output_filename)\n",
    "store_array_to_file (clustering_array, output_filename)\n",
    "'''\n",
    "\n",
    "\n",
    "# Load clustering_array[] from file:\n",
    "\n",
    "#file_name = BASE_ADDRESS + '/clusteringArrayList_Heuristic1noSC__Cardano_TXs_All__2023-02-25_223957.txt'\n",
    "#file_name = BASE_ADDRESS + '/clusteringArrayList_Heuristic2__Cardano_TXs_All__2023-03-26_110150.txt'\n",
    "file_name = BASE_ADDRESS + '/clusteringArrayList_Heuristic1noSC_AND_Heuristic2__Cardano_TXs_All__2023-03-26_141212.txt'\n",
    "\n",
    "clustering_array = load_file_to_array (file_name)\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90cc860-f2ea-4ed1-aaa6-921f3bacbb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd971ca-b1a6-487f-96fc-775b6f1ce617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge graghEdges_ Arrays:\n",
    "\n",
    "def merge_graphEdges(graghEdges_array, graghEdges_merged):\n",
    "    if (len(graghEdges_array) != len(graghEdges_merged)):\n",
    "        print('merge_graphEdges Error: -1 (Length)')\n",
    "        return -1\n",
    "    \n",
    "    for i in tqdm(range(len(graghEdges_merged))):\n",
    "        graghEdges_merged[i].extend(graghEdges_array[i])\n",
    "    \n",
    "    return\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('----------------------')\n",
    "# ct stores current time\n",
    "ct = datetime.datetime.now()\n",
    "print(\"current time: \", ct)\n",
    "\n",
    "##########################################################################################\n",
    "\n",
    "graphEdges_merged = [[] for _ in range(unique_payment_addresses_len)]\n",
    "\n",
    "\n",
    "merge_graphEdges(graghEdges_1, graphEdges_merged)\n",
    "print('graghEdges_1[] merged!')\n",
    "\n",
    "\n",
    "merge_graphEdges(graghEdges_2, graphEdges_merged)\n",
    "print('graghEdges_2[] merged!')\n",
    "\n",
    "merge_graphEdges(graghEdges_3, graphEdges_merged)\n",
    "print('graghEdges_3[] merged!')\n",
    "\n",
    "merge_graphEdges(graghEdges_4, graphEdges_merged)\n",
    "print('graghEdges_4[] merged!')\n",
    "\n",
    "merge_graphEdges(graghEdges_5, graphEdges_merged)\n",
    "print('graghEdges_5[] merged!')\n",
    "\n",
    "merge_graphEdges(graghEdges_6, graphEdges_merged)\n",
    "print('graghEdges_6[] merged!')\n",
    "\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "et = datetime.datetime.now() - ct\n",
    "print(\"Total elapsed time (Fill Clustering Array with Heuristics): \", et)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1ca0d17-bf0f-43a3-9221-06561a92a714",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ba0f3-bbd6-4a3c-b6b1-2116a057ddea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store graphEdges_merged into file:\n",
    "\n",
    "print('----------------------')\n",
    "\n",
    "ct = datetime.datetime.now()\n",
    "curr_timestamp = str(ct)[0:10] + '_' + str(ct)[11:13] + str(ct)[14:16] + str(ct)[17:19]\n",
    "#output_filename = BASE_ADDRESS + '/graphEdgesArrayList_Heuristic1_LinkToFirstAddressInTX__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "output_filename = BASE_ADDRESS + '/graphEdgesArrayList_Heuristic1noSC_LinkToALLAddressesInTX__Cardano_TXs_All__' + curr_timestamp + '.txt'\n",
    "print('output_filename = ', output_filename)\n",
    "\n",
    "store_array_to_file_2D (graphEdges_merged, output_filename)\n",
    "\n",
    "##########################################################################################\n",
    "print('----------------------')\n",
    "print('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df37d2f-361e-4b1e-9d1e-89eb27cf24c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ac60ce-3626-4f65-96fd-9e0375e7a468",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9956aaaa-702c-4774-acb3-0ed4b4a16f80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
